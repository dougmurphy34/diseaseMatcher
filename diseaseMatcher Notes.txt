Objective: Develop a citizen science game, based on ESP/Google Image Labeler model, to identify disease names in the text of biomedical research abstracts.

Features: User login/profiles, player vs. AI, time pressure, document storage and display, results storage.

Models: Artigo.org - successor to ESP
        Cyclonecenter.org and others at zooniverse.org

Tools used:     django 1.6.5 web framework (lab standard, personal preference for python over java)
		        MariaDB 10 (more feature rich than mySQL, easier administration than PostgreSQL)
		        Python 2.7
		        jQuery 1.11.1
	            Pycharm Enterprise
	            HeidiSQL
	            MySQL-python 1.2.5
	                binary from http://www.lfd.uci.edu/~gohlke/pythonlibs/
	            GitHub - source control (dougmurphy34/diseaseMatcher)
	            NO data migration - just syncdb
	                (confirmed, South does not and will not support MariaDB http://south.aeracode.org/ticket/1309)

Design Principles used:
    Unit and integration testing using unittest with frameworks
    MVC model as implemented by django
    Loose coupling
    Agile Development (Frequent functional builds)


Status of development (9/17/2014):
    Game entry:
        If user is not logged in, they are walked through a login/registration process.  New registrations automatically logged in.
        Landing page receives user, navigates to single (random but new to user) abstract display with game interface.
    Game play:
        User can mouse-highlight or type text (disease matches) for that abstract until 30 seconds passes, or they click "Done".
        Mouse highlight requires "confirm" click.
        User entry is rejected on client side if it doesn't match abstract title/text, is too long, or is a duplicate, with an explanatory message.
    Data Processing:
        Results are cleaned of dupes, spaces, tabs and problematic punctuation.
        Results are re-checked on server side for accuracy vs. title and text.  Location and offset are calculated for typed answers.
        Database records match text, length, location (title or text), offset, annotator, abstract, time into game answer was entered.
        For typed answers, each instance of typed text is recorded (offset and location).  For mouse selected, just the one actually selected is recorded.
    Post-game:
        User is given opportunity to play again or log out.
        User can view play history and ranking on user profile page.

Next steps:
    Table-based (vs. textarea-based) onscreen user results, including ability to drop a previous answer from list.  (Need a game reason to do this).
    Incorporate scoring system for matches and rankings.
    Interface for additional registration data - age, gender, occupation, purpose for playing, education  (all optional)

Future direction:
    Bifurcate game - how many abstracts can you hit a match on in 60 seconds, how many matches in this abstract in 60 seconds.  3 matches to completion?  "Banned" words?
    Build a pretty GUI - branding, images, better instructions to the user, better feedback.  Borrow some of this from Mark2Cure.org.
    Create illusion of a "partner" playing with you (AI).
    Modular layout that supports mobile using CSS media queries.
    Turn on atomic transactions (Two Scoops 6.4) - make sure this works with my table types (6.4.4)

Software Design questions:
    What functionality do we want that isn't in this document yet?

Product Design questions:
    What reports do we need to pull from all this data we are gathering?  How do we want to get the data out and present it?  Who will use the data, and how?
    Where will the project be deployed to?  Should we do this now (to a staging server) so the lab can see it?

Game design questions:
    Confirm vs. undo on adding answer via mouse selection: http://alistapart.com/article/neveruseawarning